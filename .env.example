# ============================================================================
# Agriculture Chatbot - Environment Variables
# ============================================================================
# Copy this file to .env and fill in your actual values
# cp .env.example .env
# ============================================================================

# ----------------------------------------------------------------------------
# Vector Database Configuration (Pinecone)
# ----------------------------------------------------------------------------
# Get your API key from: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=gcp-starter  # Optional: Default is gcp-starter

# ----------------------------------------------------------------------------
# OpenAI Configuration (for Embeddings)
# ----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# Used for text-embedding-ada-002 embeddings
OPENAI_API_KEY=your_openai_api_key_here

# ----------------------------------------------------------------------------
# LangSmith Observability (Optional but Recommended)
# ----------------------------------------------------------------------------
# Get your API key from: https://smith.langchain.com
# Enable tracing to monitor and debug your agentic workflows
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_WORKSPACE_ID=your_workspace_id_here  # Optional: only needed if you have multiple workspaces
LANGSMITH_PROJECT=agriculture-chatbot  # Optional: custom project name

# ----------------------------------------------------------------------------
# Ollama Configuration (Local LLM)
# ----------------------------------------------------------------------------
# No API key needed - Ollama runs locally
# Make sure Ollama is running: ollama serve
# Make sure the model is installed: ollama pull gpt-oss:20b
# Default model: gpt-oss:20b
# OLLAMA_BASE_URL=http://localhost:11434  # Optional: if Ollama is on different host/port

# ----------------------------------------------------------------------------
# FastAPI Server Configuration (Optional)
# ----------------------------------------------------------------------------
PORT=8000  # Port for the FastAPI server
HOST=0.0.0.0  # Host for the FastAPI server (0.0.0.0 for all interfaces)

# ----------------------------------------------------------------------------
# Application Configuration (Optional)
# ----------------------------------------------------------------------------
# ENVIRONMENT=development  # development, staging, production
# LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR

# ============================================================================
# Quick Setup Guide:
# ============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Fill in your API keys above
# 3. Make sure Ollama is running locally with gpt-oss:20b model
# 4. Run the ingestion pipeline: python ingest.py
# 5. Start the API server: python api.py
# ============================================================================
